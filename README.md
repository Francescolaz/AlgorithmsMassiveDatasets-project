<p align="center">
  <img width="488" height="164" src="logo.png">
</p>

# AlgorithmsMassiveDatasets-project
GitHub repository of the "Algorithm for Massive Datasets" delivered project - University of Milan, Academic Year - 2020/2021

## Project 2: Market-basket analysis
The task is to implement a system finding frequent itemsets (aka market-basket analysis).
### IMDB
The «IMDB» dataset is published on Kaggle, under IMDb non-commercial licensing. The analysis must be done considering movies as baskets and actors as items.

## Important: the techniques used in order to analyze data have to scale up to larger datasets.

The project can be carried out individually, or in groups of two students. Code should be written in Python 3.
The project should be made available through a public github repository, containing code and a report describing the work done. The dataset should not be added to the repository, but downloaded during code execution, for instance via the kaggle API
(https://github.com/Kaggle/kaggle-api). Code should be implemented using a jupyter notebook executable on Google colab, possibly adding a badge/link directly from the repository to the colab version of the notebook.
The project report, preferably written in LaTeX, will be evaluated according to the following criteria:

- correctness of the general methodological approach,
- replicability of the experiments,
- correctness of the approach,
- scalability of the proposed solution,
- clarity of exposition.

The report should contain the following information:
1. the chosen dataset, and the parts of the latter which have been considered,
  
2. how data have been organized,
3. the applied pre-processing techniques,
4. the considered algorithms and their implementations,
5. how the proposed solution scales up with data size,
6. a description of the experiments,
7. comments and discussion on the experimental results.
